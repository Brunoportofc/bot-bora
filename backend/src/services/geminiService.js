import { GoogleGenerativeAI } from '@google/generative-ai';
import fs from 'fs';
import path from 'path';
import { createRequire } from 'module';
import logger from '../config/logger.js';

// Usar createRequire para carregar pdf-parse (CommonJS) em ES module
const require = createRequire(import.meta.url);
let pdfParse;

// Cache de histÃ³rico por nÃºmero de telefone
const userConversations = new Map();

// ConfiguraÃ§Ãµes fixas do sistema
const FIXED_MODEL = 'gemini-2.5-flash';
const FIXED_TEMPERATURE = 1.0;

// Diretrizes fixas que SEMPRE serÃ£o aplicadas
const SYSTEM_GUIDELINES = `
Diretrizes:
- Seja sempre educado e respeitoso
- ForneÃ§a respostas precisas e Ãºteis
- Se nÃ£o souber algo, admita honestamente
- Adapte seu tom ao contexto da conversa
- Mantenha as respostas concisas quando possÃ­vel
`;

/**
 * Combina o prompt personalizado do usuÃ¡rio com as diretrizes fixas do sistema
 */
function buildSystemPrompt(customPrompt = '') {
  if (customPrompt && customPrompt.trim()) {
    return `${customPrompt.trim()}\n\n${SYSTEM_GUIDELINES}`;
  }
  return `VocÃª Ã© um assistente virtual prestativo e profissional.\n${SYSTEM_GUIDELINES}`;
}

/**
 * Processa uma mensagem usando Google Gemini
 */
export async function processMessageWithGemini(messageText, phoneNumber, apiKey, modelName = FIXED_MODEL, systemPrompt = '', temperature = FIXED_TEMPERATURE) {
  try {
    const genAI = new GoogleGenerativeAI(apiKey);
    console.log("enviando para gemini", messageText);
    
    // Sempre usar configuraÃ§Ãµes fixas + prompt personalizado
    const finalSystemPrompt = buildSystemPrompt(systemPrompt);
    
    // Criar chave Ãºnica APENAS com phoneNumber para manter histÃ³rico contÃ­nuo
    const conversationKey = phoneNumber;
    
    // Obter ou criar histÃ³rico de conversa para este usuÃ¡rio
    let conversationData = userConversations.get(conversationKey);
    
    if (!conversationData) {
      // Criar nova conversa APENAS se nÃ£o existir
      // ConfiguraÃ§Ã£o do modelo
      const model = genAI.getGenerativeModel({ 
        model: FIXED_MODEL,
        generationConfig: {
          temperature: FIXED_TEMPERATURE,
          topP: 0.95,
          topK: 40,
          maxOutputTokens: 8192,
        },
        systemInstruction: finalSystemPrompt
      });
      
      const chat = model.startChat({
        history: [],
      });
      
      conversationData = {
        chat,
        model,
        systemPrompt: finalSystemPrompt
      };
      
      userConversations.set(conversationKey, conversationData);
      logger.info(`ðŸ†• Nova conversa iniciada para ${phoneNumber}`);
    } else {
      logger.info(`â™»ï¸ Usando conversa existente para ${phoneNumber} (${userConversations.get(conversationKey).chat.history?.length || 0} mensagens no histÃ³rico)`);
    }
    
    const { chat } = conversationData;

    logger.info('===== ENVIANDO MENSAGEM PARA GEMINI =====');
    logger.info(`Telefone: ${phoneNumber}`);
    logger.info(`Modelo: ${FIXED_MODEL} (fixo)`);
    logger.info(`Temperatura: ${FIXED_TEMPERATURE} (fixa)`);
    logger.info(`Prompt Personalizado: ${systemPrompt || 'Nenhum'}`);
    logger.info(`Prompt Final (com diretrizes): ${finalSystemPrompt.substring(0, 100)}...`);
    logger.info(`Mensagem (${messageText.length} caracteres):`, messageText);
    logger.info('==========================================');
    
    try {
      const result = await chat.sendMessage(messageText);
      const response = result.response;
  
      // VERIFICAÃ‡ÃƒO DE SEGURANÃ‡A: Checa se a resposta tem conteÃºdo vÃ¡lido
      if (response.candidates && response.candidates.length > 0 && response.candidates[0].content) {
        const responseText = response.text(); // Agora Ã© seguro chamar .text()
        
        logger.info('===== RESPOSTA VÃLIDA RECEBIDA DO GEMINI =====');
        logger.info(`Telefone: ${phoneNumber}`);
        logger.info(`Resposta (${responseText.length} caracteres): ${responseText}`);
        logger.info('========================================');
        
        return responseText;
  
      } else {
        // A API respondeu, mas bloqueou a resposta ou nÃ£o gerou conteÃºdo.
        const finishReason = response.candidates?.[0]?.finishReason || 'Desconhecido';
        logger.warn('===== RESPOSTA DO GEMINI SEM CONTEÃšDO =====');
        logger.warn(`Telefone: ${phoneNumber}`);
        logger.warn(`Motivo do tÃ©rmino: ${finishReason}`);
        logger.warn('Resposta completa para depuraÃ§Ã£o:', JSON.stringify(response, null, 2));
        logger.warn('=========================================');
  
        // Retorne uma mensagem padrÃ£o para o usuÃ¡rio final
        return "Desculpe, nÃ£o consegui processar sua mensagem. Por favor, tente reformulÃ¡-la.";
      }
    } catch (error) {
      // Registrar como WARN: a chamada ao Gemini falhou, mas retornamos uma mensagem de fallback
      // para que a conversa do usuÃ¡rio continue (evita crash no pipeline).
      logger.warn('Erro ao processar mensagem com Gemini (retornando fallback):', error);
      return 'Desculpe, estou com dificuldades para processar sua mensagem no momento. Tente novamente em instantes.';
    }
  } catch (error) {
    logger.error('âŒ ERRO COMPLETO AO PROCESSAR COM GEMINI:');
    logger.error('==============================================');
    
    // Log do erro bruto primeiro
    logger.error('ERRO BRUTO:', error);
    logger.error('Tipo do erro:', typeof error);
    logger.error('Construtor:', error?.constructor?.name);
    
    // Propriedades bÃ¡sicas
    if (error?.message) logger.error('Mensagem:', error.message);
    if (error?.name) logger.error('Nome:', error.name);
    if (error?.stack) logger.error('Stack:', error.stack);
    if (error?.code) logger.error('Code:', error.code);
    if (error?.status) logger.error('Status:', error.status);
    if (error?.statusText) logger.error('Status Text:', error.statusText);
    
    // Propriedades do Gemini SDK
    if (error?.response) {
      logger.error('Response existe:', true);
      logger.error('Response:', JSON.stringify(error.response, null, 2));
    }
    
    if (error?.data) {
      logger.error('Data existe:', true);
      logger.error('Data:', JSON.stringify(error.data, null, 2));
    }
    
    if (error?.error) {
      logger.error('Error object existe:', true);
      logger.error('Error object:', JSON.stringify(error.error, null, 2));
    }
    
    // Todas as chaves do objeto de erro
    logger.error('Chaves do erro:', Object.keys(error || {}));
    logger.error('Propriedades prÃ³prias:', Object.getOwnPropertyNames(error || {}));
    
    // Tentar serializar o erro completo
    try {
      logger.error('JSON completo:', JSON.stringify(error, Object.getOwnPropertyNames(error), 2));
    } catch (e) {
      logger.error('NÃ£o foi possÃ­vel serializar o erro:', e.message);
    }
    
    // InspeÃ§Ã£o completa
    try {
      logger.error('InspeÃ§Ã£o do erro:', require('util').inspect(error, { depth: 5, colors: false }));
    } catch (e) {
      logger.error('NÃ£o foi possÃ­vel inspecionar o erro');
    }
    
    logger.error('==============================================');
    
    // Tratamento especÃ­fico de erros
    const errorMsg = error?.message || error?.toString() || 'Erro desconhecido';
    
    if (errorMsg.includes('API_KEY_INVALID') || errorMsg.includes('API key') || errorMsg.includes('API_KEY') || errorMsg.includes('invalid')) {
      logger.error('âŒ API Key invÃ¡lida ou sem permissÃ£o');
      return 'Desculpe, a API Key do Gemini estÃ¡ invÃ¡lida. Verifique sua configuraÃ§Ã£o.';
    }
    
    if (errorMsg.includes('quota') || errorMsg.includes('limit') || errorMsg.includes('RESOURCE_EXHAUSTED')) {
      logger.error('âŒ Limite de uso excedido');
      return 'Desculpe, o limite de uso da API foi excedido. Aguarde alguns minutos.';
    }

    return 'Desculpe, estou com dificuldades para processar sua mensagem no momento. Tente novamente em instantes.';
  }
}

/**
 * Transcreve Ã¡udio usando Google Gemini (ainda nÃ£o suportado - usar Whisper API)
 */
export async function transcribeAudio(audioBuffer, apiKey, prompt = '') {
  try {
    logger.info('Iniciando transcriÃ§Ã£o de Ã¡udio...', {
      bufferSize: audioBuffer.length,
      bufferType: typeof audioBuffer,
      isBuffer: Buffer.isBuffer(audioBuffer)
    });

    if (!Buffer.isBuffer(audioBuffer)) {
      throw new Error('audioBuffer deve ser um Buffer vÃ¡lido');
    }

    if (audioBuffer.length === 0) {
      throw new Error('Buffer de Ã¡udio estÃ¡ vazio');
    }

    // Nota: Gemini ainda nÃ£o suporta transcriÃ§Ã£o de Ã¡udio nativamente
    // Alternativa: usar Google Speech-to-Text ou Whisper API
    logger.warn('TranscriÃ§Ã£o de Ã¡udio com Gemini ainda nÃ£o implementada');
    return 'Desculpe, ainda nÃ£o consigo processar Ã¡udios. Por favor, envie sua mensagem como texto.';
  } catch (error) {
    logger.error('âŒ ERRO ao transcrever Ã¡udio:');
    logger.error('Mensagem:', error.message);
    logger.error('Stack:', error.stack);
    throw error;
  }
}

/**
 * Analisa imagem usando Google Gemini Vision
 */
export async function analyzeImage(imageBuffer, apiKey, modelName = FIXED_MODEL, prompt = '', systemPrompt = '') {
  try {
    logger.info('Iniciando anÃ¡lise de imagem com Gemini...', {
      bufferSize: imageBuffer.length,
      bufferType: typeof imageBuffer,
      isBuffer: Buffer.isBuffer(imageBuffer)
    });

    if (!Buffer.isBuffer(imageBuffer)) {
      throw new Error('imageBuffer deve ser um Buffer vÃ¡lido');
    }

    if (imageBuffer.length === 0) {
      throw new Error('Buffer de imagem estÃ¡ vazio');
    }

    const genAI = new GoogleGenerativeAI(apiKey);
    const finalSystemPrompt = buildSystemPrompt(systemPrompt || 'VocÃª Ã© um assistente especializado em anÃ¡lise de imagens.');
    
    const model = genAI.getGenerativeModel({ 
      model: FIXED_MODEL,
      systemInstruction: finalSystemPrompt
    });

    // Converter buffer para base64
    const base64Image = imageBuffer.toString('base64');
    
    logger.info('Enviando imagem para Gemini Vision...');

    // Criar partes da mensagem: texto + imagem
    const imagePart = {
      inlineData: {
        data: base64Image,
        mimeType: 'image/jpeg'
      }
    };

    const textPart = prompt || "Analise esta imagem em detalhes. Descreva exatamente o que vocÃª vÃª, incluindo:\n- Se for uma imagem mÃ©dica (raio-X, ressonÃ¢ncia, etc.), descreva as estruturas anatÃ´micas visÃ­veis\n- Qualquer texto presente na imagem\n- Objetos, pessoas, cores e elementos visuais\n- Qualquer informaÃ§Ã£o relevante ou anormalidade observada\n- Se houver texto na imagem, transcreva-o completamente\n\nSeja especÃ­fico e detalhado na sua anÃ¡lise.";

    const result = await model.generateContent([textPart, imagePart]);
    const analysis = result.response.text();
    
    logger.info('Imagem analisada com sucesso:', {
      analysisLength: analysis.length,
      preview: analysis.substring(0, 100)
    });

    return analysis;
  } catch (error) {
    logger.error('Erro detalhado ao analisar imagem:', error);
    throw error;
  }
}

/**
 * Processa documento (PDF, DOC, etc.) convertendo para texto
 */
export async function processDocument(documentBuffer, filename) {
  try {
    logger.info('Iniciando processamento de documento...', {
      filename,
      bufferSize: documentBuffer.length,
      fileExtension: path.extname(filename).toLowerCase()
    });

    const fileExtension = path.extname(filename).toLowerCase();
    
    // Para PDFs, usar uma biblioteca de extraÃ§Ã£o de texto
    if (fileExtension === '.pdf') {
      return await extractTextFromPDF(documentBuffer);
    }
    
    // Para outros documentos, tentar converter para texto
    if (['.doc', '.docx', '.txt', '.rtf'].includes(fileExtension)) {
      // Se for texto simples, tentar ler diretamente
      if (fileExtension === '.txt') {
        const text = documentBuffer.toString('utf-8');
        logger.info('Texto extraÃ­do do arquivo .txt');
        return text;
      }
      
      // Para outros formatos, retornar informaÃ§Ã£o bÃ¡sica
      return `Documento ${filename} recebido. Formato: ${fileExtension}. Tamanho: ${documentBuffer.length} bytes. Para melhor anÃ¡lise, converta para PDF ou imagem.`;
    }

    throw new Error(`Formato de arquivo nÃ£o suportado: ${fileExtension}`);
  } catch (error) {
    logger.error('Erro ao processar documento:', error);
    throw error;
  }
}

/**
 * Extrai texto de PDF usando pdf-parse
 */
async function extractTextFromPDF(pdfBuffer) {
  try {
    logger.info('Iniciando extraÃ§Ã£o de texto do PDF...');

    if (!Buffer.isBuffer(pdfBuffer)) {
      throw new Error('pdfBuffer deve ser um Buffer vÃ¡lido');
    }

    if (pdfBuffer.length === 0) {
      throw new Error('Buffer de PDF estÃ¡ vazio');
    }

    // Carregar pdf-parse
    if (!pdfParse) {
      try {
        pdfParse = require('pdf-parse/lib/pdf-parse.js');
        logger.info('pdf-parse carregado com sucesso');
      } catch (error) {
        logger.error('Erro ao carregar pdf-parse:', error.message);
        throw new Error('Biblioteca de processamento de PDF nÃ£o disponÃ­vel');
      }
    }

    // Extrair texto do PDF
    const data = await pdfParse(pdfBuffer);
    
    const extractedText = data.text.trim();
    const numPages = data.numpages;
    const info = data.info;

    logger.info('PDF processado com sucesso:', {
      numPages,
      textLength: extractedText.length,
      title: info?.Title || 'Sem tÃ­tulo',
    });

    if (!extractedText || extractedText.length === 0) {
      return `Este PDF contÃ©m ${numPages} pÃ¡gina(s), mas nÃ£o foi possÃ­vel extrair texto diretamente. O documento pode conter apenas imagens ou ser um PDF escaneado.`;
    }

    // Formatar informaÃ§Ãµes do PDF
    let result = '';
    
    if (info?.Title && info.Title !== 'Untitled') {
      result += `TÃTULO: ${info.Title}\n`;
    }
    
    if (numPages) {
      result += `PÃGINAS: ${numPages}\n`;
    }
    
    result += `\n${'='.repeat(60)}\n`;
    result += `CONTEÃšDO DO DOCUMENTO:\n`;
    result += `${'='.repeat(60)}\n\n`;
    result += extractedText;

    return result;
  } catch (error) {
    logger.error('Erro ao extrair texto do PDF:', error);
    return `NÃ£o foi possÃ­vel extrair o texto deste PDF. O documento pode estar protegido, corrompido, ou conter apenas imagens.`;
  }
}

/**
 * Processa mensagem com imagem usando Gemini Vision
 */
export async function processImageMessageWithGemini(imageBuffer, phoneNumber, apiKey, modelName = FIXED_MODEL, systemPrompt = '', temperature = FIXED_TEMPERATURE, caption = '') {
  try {
    logger.info(`Processando mensagem com imagem para ${phoneNumber} - Modelo: ${FIXED_MODEL}`);
    
    // Criar prompt combinado
    let fullPrompt = '';
    
    if (caption && caption.trim()) {
      fullPrompt = `O usuÃ¡rio enviou uma imagem com o seguinte comentÃ¡rio/pergunta:\n"${caption}"\n\nPor favor, analise a imagem e responda considerando o comentÃ¡rio do usuÃ¡rio.`;
    } else {
      fullPrompt = 'Analise esta imagem e forneÃ§a uma resposta detalhada e Ãºtil.';
    }
    
    // Analisar a imagem diretamente com o Gemini (sempre usa configuraÃ§Ãµes fixas)
    const analysis = await analyzeImage(imageBuffer, apiKey, FIXED_MODEL, fullPrompt, systemPrompt);
    
    logger.info('Imagem processada com Gemini Vision');
    
    return {
      imageAnalysis: analysis,
      aiResponse: analysis,
      caption
    };
  } catch (error) {
    logger.error('Erro ao processar mensagem com imagem:', error);
    throw error;
  }
}

/**
 * Processa mensagem com documento usando Gemini
 */
export async function processDocumentMessageWithGemini(documentBuffer, filename, phoneNumber, apiKey, modelName = FIXED_MODEL, systemPrompt = '', temperature = FIXED_TEMPERATURE, caption = '') {
  try {
    logger.info(`Processando documento para ${phoneNumber}: ${filename} - Modelo: ${FIXED_MODEL}`);
    
    // 1. Processar o documento
    const documentContent = await processDocument(documentBuffer, filename);
    logger.info(`Documento processado: "${documentContent.substring(0, 100)}..."`);
    
    // 2. Criar prompt para anÃ¡lise do documento
    let fullMessage = `CONTEXTO: Um usuÃ¡rio enviou um documento (${filename}).\n\nCONTEÃšDO EXTRAÃDO DO DOCUMENTO:\n${documentContent}`;
    
    if (caption && caption.trim()) {
      fullMessage += `\n\nCOMENTÃRIO/PERGUNTA DO USUÃRIO:\n"${caption}"`;
    }
    
    fullMessage += `\n\nPor favor, analise o conteÃºdo do documento e forneÃ§a uma resposta Ãºtil e clara.`;
    
    // 3. Processar com o Gemini (sempre usa configuraÃ§Ãµes fixas)
    const aiResponse = await processMessageWithGemini(fullMessage, phoneNumber, apiKey, FIXED_MODEL, systemPrompt, FIXED_TEMPERATURE);
    
    return {
      documentContent,
      aiResponse,
      caption,
      filename
    };
  } catch (error) {
    logger.error('Erro ao processar mensagem com documento:', error);
    throw error;
  }
}

/**
 * Processa mensagem de Ã¡udio usando Gemini
 */
export async function processAudioMessageWithGemini(audioBuffer, phoneNumber, apiKey, modelName = FIXED_MODEL, systemPrompt = '', temperature = FIXED_TEMPERATURE) {
  try {
    logger.info(`ðŸŽ¤ Processando mensagem de Ã¡udio para ${phoneNumber}`, {
      audioSize: audioBuffer.length,
      model: FIXED_MODEL
    });

    const genAI = new GoogleGenerativeAI(apiKey);
    
    // Converter buffer para base64
    const base64Audio = audioBuffer.toString('base64');
    
    // Sempre usar configuraÃ§Ãµes fixas + prompt personalizado
    const finalSystemPrompt = buildSystemPrompt(systemPrompt);
    
    // Criar chave Ãºnica APENAS com phoneNumber para manter histÃ³rico contÃ­nuo (mesma chave que texto!)
    const conversationKey = phoneNumber;
    
    // Obter ou criar histÃ³rico de conversa para este usuÃ¡rio
    let conversationData = userConversations.get(conversationKey);
    
    if (!conversationData) {
      // Criar nova conversa APENAS se nÃ£o existir
      // ConfiguraÃ§Ã£o do modelo
      const model = genAI.getGenerativeModel({ 
        model: FIXED_MODEL,
        generationConfig: {
          temperature: FIXED_TEMPERATURE,
          topP: 0.95,
          topK: 40,
          maxOutputTokens: 8192,
        },
        systemInstruction: finalSystemPrompt
      });
      
      const chat = model.startChat({
        history: [],
      });
      
      conversationData = {
        chat,
        model,
        systemPrompt: finalSystemPrompt
      };
      
      userConversations.set(conversationKey, conversationData);
      logger.info(`ðŸ†• Nova conversa iniciada para Ã¡udio de ${phoneNumber}`);
    } else {
      logger.info(`â™»ï¸ Usando conversa existente para Ã¡udio de ${phoneNumber} (${userConversations.get(conversationKey).chat.history?.length || 0} mensagens no histÃ³rico)`);
    }
    
    const { model, chat } = conversationData;

    logger.info(`ðŸŽ¤ Enviando Ã¡udio para transcriÃ§Ã£o e anÃ¡lise...`);

    // Primeiro, obter a transcriÃ§Ã£o (usa o mesmo modelo do chat!)
    const transcriptionResult = await model.generateContent([
      {
        inlineData: {
          mimeType: "audio/ogg",
          data: base64Audio
        }
      },
      "Transcreva este Ã¡udio em portuguÃªs, mantendo toda a pontuaÃ§Ã£o e emoÃ§Ã£o da mensagem original."
    ]);

    const transcription = transcriptionResult.response.text();
    logger.info(`âœ… TranscriÃ§Ã£o obtida: "${transcription.substring(0, 100)}..."`);

    // Agora, gerar resposta baseada na transcriÃ§Ã£o usando o MESMO chat
    logger.info(`ðŸ¤– Iniciando geraÃ§Ã£o de resposta para Ã¡udio...`);
    logger.info(`ðŸ“¤ Enviando transcriÃ§Ã£o para gerar resposta...`);
    
    const result = await chat.sendMessage(`[Mensagem de Ãudio]: ${transcription}`);
    const aiResponse = result.response.text();

    logger.info(`âœ… Resposta gerada para Ã¡udio: "${aiResponse.substring(0, 100)}..."`);

    // NÃ£o precisa atualizar histÃ³rico manualmente - o chat.sendMessage jÃ¡ faz isso

    return {
      transcription,
      aiResponse
    };

  } catch (error) {
    logger.error('âŒ Erro ao processar mensagem de Ã¡udio:', {
      error: error.message,
      stack: error.stack,
      phoneNumber,
      errorType: error.constructor.name,
      errorCode: error.code,
      errorStatus: error.status
    });
    
    // Log do erro completo para debug
    logger.error('Detalhes completos do erro:', error);

    // Fallback em caso de erro
    return {
      transcription: '[Erro ao transcrever]',
      aiResponse: 'Desculpe, tive dificuldade em processar seu Ã¡udio. Pode enviar como texto ou tentar novamente?'
    };
  }
}

/**
 * Limpa o histÃ³rico de conversa de um usuÃ¡rio
 */
export function clearUserConversation(phoneNumber) {
  // Limpar todas as conversas deste nÃºmero (pode ter mÃºltiplos system prompts)
  const keysToDelete = [];
  for (const key of userConversations.keys()) {
    if (key.startsWith(phoneNumber)) {
      keysToDelete.push(key);
    }
  }
  keysToDelete.forEach(key => userConversations.delete(key));
  logger.info(`Conversa(s) removida(s) para ${phoneNumber}`);
}

/**
 * Limpa todas as conversas
 */
export function clearAllConversations() {
  userConversations.clear();
  logger.info('Todas as conversas foram limpas');
}

/**
 * ObtÃ©m estatÃ­sticas das conversas ativas
 */
export function getConversationsStats() {
  return {
    activeConversations: userConversations.size,
    conversations: Array.from(userConversations.keys()).map(phone => ({
      phoneNumber: phone
    }))
  };
}

